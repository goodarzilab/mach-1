{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1abfb5a-18e0-4e22-9cd1-415255c2e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from modeling_hyena import StripedHyenaModelForCausalLM\n",
    "\n",
    "from datasets import load_from_disk, concatenate_datasets\n",
    "from accelerate.utils import set_seed\n",
    "from transformers import (\n",
    "    set_seed as transformers_set_seed,\n",
    "    PreTrainedTokenizerFast,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "transformers_set_seed(SEED)\n",
    "\n",
    "checkpoint = \"../weights\"\n",
    "model = StripedHyenaModelForCausalLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf65527-cc02-4dd2-ad31-991ca1b04fe1",
   "metadata": {},
   "source": [
    "```\n",
    "get_block\n",
    "    raise NotImplementedError\n",
    "NotImplementedError\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554702f7-2cc4-4601-9ce6-1da4f29e1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"../weights/model.safetensors\"\n",
    "model = StripedHyenaModelForCausalLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67183de-a14a-43b0-ac43-7d443c244f25",
   "metadata": {},
   "source": [
    "```\n",
    "OSError: Incorrect path_or_model_id: '../weights/model.safetensors'. Please provide either the path to a local folder or the repo_id of a model on the Hub.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00abebf-e83c-46d4-98cc-38b3f36c5c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configuration_hyena import StripedHyenaConfig\n",
    "\n",
    "config_dict = {\n",
    "    \"vocab_size\": 32,                   \n",
    "    \"hidden_size\": 128,                 \n",
    "    \"num_filters\": 128,                 \n",
    "    \"inner_mlp_size\": 352,             \n",
    "    \"attn_layer_idxs\": [4, 8, 12],      \n",
    "    \"hyena_layer_idxs\": [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 13, 14, 15],\n",
    "    \"num_layers\": 16,                   \n",
    "    \"tie_embeddings\": True,            \n",
    "    \"short_filter_length\": 3,          \n",
    "    \"num_attention_heads\": 16,         \n",
    "    \"proj_groups\": 1,                  \n",
    "    \"hyena_filter_groups\": 1,          \n",
    "    \"split_k0\": True,                  \n",
    "    \"column_split_hyena\": True,        \n",
    "    \"column_split\": False,             \n",
    "    \"model_parallel_size\": 1,          \n",
    "    \"pipe_parallel_size\": 1,           \n",
    "    \"short_filter_bias\": True,         \n",
    "    \"mha_out_proj_bias\": True,         \n",
    "    \"qkv_proj_bias\": True,             \n",
    "    \"final_norm\": True,                \n",
    "    \"use_cache\": False,                \n",
    "    \"use_flash_attention_2\": True,     \n",
    "    \"use_flash_rmsnorm\": True,         \n",
    "    \"use_flash_depthwise\": False,      \n",
    "    \"use_flashfft\": False,             \n",
    "    \"inference_mode\": True,            \n",
    "    \"prefill_style\": \"fft\",            \n",
    "    \"max_seqlen\": 65536,               \n",
    "    \"eps\": 1e-5,                       \n",
    "    \"state_size\": 8,                   \n",
    "    \"rotary_emb_base\": 500000,         \n",
    "    \"smeared_gqa\": False,              \n",
    "    \"make_vocab_size_divisible_by\": 8,  \n",
    "    \"log_intermediate_values\": False,   \n",
    "    \"bidirectional\": False              \n",
    "}\n",
    "\n",
    "config = StripedHyenaConfig(**config_dict)\n",
    "checkpoint = \"../weights\"\n",
    "model = StripedHyenaModelForCausalLM.from_pretrained(checkpoint, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523918f-1dd4-4e0d-b6e6-89d692a95956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configuration_hyena import StripedHyenaConfig\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "config_dict = {\n",
    "    \"vocab_size\": 32,                   \n",
    "    \"hidden_size\": 128,                 \n",
    "    \"num_filters\": 128,                 \n",
    "    \"inner_mlp_size\": 352,             \n",
    "    \"attn_layer_idxs\": [4, 8, 12],      \n",
    "    \"hyena_layer_idxs\": [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 13, 14, 15],\n",
    "    \"num_layers\": 16,                   \n",
    "    \"tie_embeddings\": True,            \n",
    "    \"short_filter_length\": 3,          \n",
    "    \"num_attention_heads\": 16,         \n",
    "    \"proj_groups\": 1,                  \n",
    "    \"hyena_filter_groups\": 1,          \n",
    "    \"split_k0\": True,                  \n",
    "    \"column_split_hyena\": True,        \n",
    "    \"column_split\": False,             \n",
    "    \"model_parallel_size\": 1,          \n",
    "    \"pipe_parallel_size\": 1,           \n",
    "    \"short_filter_bias\": True,         \n",
    "    \"mha_out_proj_bias\": True,         \n",
    "    \"qkv_proj_bias\": True,             \n",
    "    \"final_norm\": True,                \n",
    "    \"use_cache\": False,                \n",
    "    \"use_flash_attention_2\": True,     \n",
    "    \"use_flash_rmsnorm\": True,         \n",
    "    \"use_flash_depthwise\": False,      \n",
    "    \"use_flashfft\": False,             \n",
    "    \"inference_mode\": True,            \n",
    "    \"prefill_style\": \"fft\",            \n",
    "    \"max_seqlen\": 65536,               \n",
    "    \"eps\": 1e-5,                       \n",
    "    \"state_size\": 8,                   \n",
    "    \"rotary_emb_base\": 500000,         \n",
    "    \"smeared_gqa\": False,              \n",
    "    \"make_vocab_size_divisible_by\": 8,  \n",
    "    \"log_intermediate_values\": False,   \n",
    "    \"bidirectional\": False              \n",
    "}\n",
    "\n",
    "config = StripedHyenaConfig(**config_dict)\n",
    "model = StripedHyenaModelForCausalLM(config)\n",
    "\n",
    "checkpoint = \"../weights/model.safetensors\"\n",
    "state_dict = load_file(checkpoint)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b12c9-1769-47a3-8eac-c2bdc4147d29",
   "metadata": {},
   "source": [
    "```\n",
    "raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
    "RuntimeError: Error(s) in loading state_dict for StripedHyenaModelForCausalLM:\n",
    "Missing key(s) in state_dict: \"backbone.unembed.weight\".\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a6783-416f-456b-bf66-69353770b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model state_dict:\", [k for k in model.state_dict().keys() if \"blocks\" not in k])\n",
    "print(\"model.safetensors:\", [k for k in state_dict.keys() if \"blocks\" not in k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af36c7-6641-4d7b-9c66-864003a7403d",
   "metadata": {},
   "source": [
    "```\n",
    "model state_dict: ['backbone.embedding_layer.weight', 'backbone.norm.scale', 'backbone.unembed.weight']\n",
    "model.safetensors: ['backbone.embedding_layer.weight', 'backbone.norm.scale']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a00f78-0c54-47d6-9813-617266e35dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dfa6ad-b240-4831-8f92-655db91a104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_hyena import StripedHyenaModelForCausalLM, StripedHyenaModelForExtractingEmbeddings\n",
    "from configuration_hyena import StripedHyenaConfig\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"../processing-seqs/lornash_tokenizer.json\",\n",
    "    padding_side='right',\n",
    "    truncation_side='right',\n",
    "    cls_token='[CLS]',\n",
    "    bos_token='[CLS]',\n",
    "    sep_token='[SEP]',\n",
    "    eos_token='[SEP]',\n",
    "    unk_token='[UNK]',\n",
    "    mask_token='[MASK]',\n",
    "    pad_token='[PAD]',\n",
    "    model_max_length=2**16\n",
    ")\n",
    "\n",
    "config_dict = {\n",
    "    \"vocab_size\": 32,                   \n",
    "    \"hidden_size\": 128,                 \n",
    "    \"num_filters\": 128,                 \n",
    "    \"inner_mlp_size\": 352,             \n",
    "    \"attn_layer_idxs\": [4, 8, 12],      \n",
    "    \"hyena_layer_idxs\": [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 13, 14, 15],\n",
    "    \"num_layers\": 16,                   \n",
    "    \"tie_embeddings\": True,            \n",
    "    \"short_filter_length\": 3,          \n",
    "    \"num_attention_heads\": 16,         \n",
    "    \"proj_groups\": 1,                  \n",
    "    \"hyena_filter_groups\": 1,          \n",
    "    \"split_k0\": True,                  \n",
    "    \"column_split_hyena\": True,        \n",
    "    \"column_split\": False,             \n",
    "    \"model_parallel_size\": 1,          \n",
    "    \"pipe_parallel_size\": 1,           \n",
    "    \"short_filter_bias\": True,         \n",
    "    \"mha_out_proj_bias\": True,         \n",
    "    \"qkv_proj_bias\": True,             \n",
    "    \"final_norm\": True,                \n",
    "    \"use_cache\": False,                \n",
    "    \"use_flash_attention_2\": True,     \n",
    "    \"use_flash_rmsnorm\": True,         \n",
    "    \"use_flash_depthwise\": False,      \n",
    "    \"use_flashfft\": False,             \n",
    "    \"inference_mode\": True,            \n",
    "    \"prefill_style\": \"fft\",            \n",
    "    \"max_seqlen\": 65536,               \n",
    "    \"eps\": 1e-5,                       \n",
    "    \"state_size\": 8,                   \n",
    "    \"rotary_emb_base\": 500000,         \n",
    "    \"smeared_gqa\": False,              \n",
    "    \"make_vocab_size_divisible_by\": 8,  \n",
    "    \"log_intermediate_values\": False,   \n",
    "    \"bidirectional\": False}\n",
    "\n",
    "config = StripedHyenaConfig(**config_dict)\n",
    "\n",
    "checkpoint = \"../weights\"\n",
    "model = StripedHyenaModelForCausalLM.from_pretrained(checkpoint, config=config)\n",
    "model = StripedHyenaModelForExtractingEmbeddings.from_pretrained(checkpoint, tokenizer=tokenizer, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2cab7e-9336-4243-8e4c-4137a27477ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
